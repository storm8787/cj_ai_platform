"""
íšŒì˜ìš”ì•½ê¸° API (GPT ê¸°ë°˜)
"""
import os
import re
import time
from fastapi import APIRouter, HTTPException, UploadFile, File, Form
from pydantic import BaseModel
from typing import Optional, Dict, List, Any
from openai import OpenAI

from config import settings

router = APIRouter()

# OpenAI í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key=settings.OPENAI_API_KEY)

# ëª¨ë¸ ì„¤ì •
FULL_MODEL = "gpt-4o"
SUMMARY_TOKENS = 3000

# ì¶©ì£¼ì‹œ ë¶€ì„œ/ì§€ì—­ ë°ì´í„° (í•˜ë“œì½”ë”©)
DEPARTMENTS = [
    "í™ë³´ë‹´ë‹¹ê´€", "ê°ì‚¬ë‹´ë‹¹ê´€", "ì•ˆì „í–‰ì •êµ­", "ìì¹˜í–‰ì •ê³¼", "ê¸°íšì˜ˆì‚°ê³¼", "ì•ˆì „ì´ê´„ê³¼",
    "ì •ë³´í†µì‹ ê³¼", "íšŒê³„ê³¼", "ê²½ì œêµí†µêµ­", "ê²½ì œê³¼", "íˆ¬ììœ ì¹˜ê³¼", "ì‹ ì„±ì¥ì‚°ì—…ê³¼",
    "êµí†µì •ì±…ê³¼", "ì°¨ëŸ‰ë¯¼ì›ê³¼", "ê±´ì„¤êµ­", "í—ˆê°€ë¯¼ì›ê³¼", "ë„ì‹œê³„íšê³¼", "ê±´ì¶•ê³¼",
    "ë„ë¡œê³¼", "ë³µì§€êµ­", "ë³µì§€ì •ì±…ê³¼", "ë…¸ì¸ë³µì§€ê³¼", "ì¥ì• ì¸ë³µì§€ê³¼", "ì—¬ì„±ì²­ì†Œë…„ê³¼",
    "ìƒí™œë¯¼ì›êµ­", "ë¯¼ì›ë´‰ì‚¬ê³¼", "í† ì§€ì •ë³´ê³¼", "ì„¸ì •ê³¼", "ì§•ìˆ˜ê³¼", "ìœ„ìƒê³¼",
    "ë¬¸í™”ì²´ìœ¡ê´€ê´‘êµ­", "ë¬¸í™”ì˜ˆìˆ ê³¼", "ì²´ìœ¡ì§„í¥ê³¼", "ê´€ê´‘ê³¼", "í‰ìƒí•™ìŠµê³¼",
    "ë†ì—…ì •ì±…êµ­", "ë†ì •ê³¼", "ì¹œí™˜ê²½ë†ì‚°ê³¼", "ë†ì‹í’ˆìœ í†µê³¼", "ì¶•ìˆ˜ì‚°ê³¼",
    "í‘¸ë¥¸ë„ì‹œêµ­", "ì •ì›ë„ì‹œê³¼", "ê· í˜•ê°œë°œê³¼", "í•˜ì²œê³¼", "ì‚°ë¦¼ê³¼",
    "í™˜ê²½êµ­", "ìˆ˜ì§ˆí™˜ê²½ê³¼", "ëŒ€ê¸°í™˜ê²½ê³¼", "ìì›ìˆœí™˜ê³¼",
    "ë³´ê±´ì†Œ", "ë³´ê±´ê³¼", "ê±´ê°•ì¦ì§„ê³¼", "ì§ˆë³‘ê´€ë¦¬ê³¼",
    "ë†ì—…ê¸°ìˆ ì„¼í„°", "ë†ì—…ê¸°ìˆ ê³¼", "ë†ì—…êµìœ¡ê³¼", "ê³¼ìˆ˜ìœ¡ì„±ê³¼",
    "ìƒìˆ˜ë„ì‚¬ì—…ì†Œ", "í•˜ìˆ˜ë„ì‚¬ì—…ì†Œ", "ì‹œë¦½ë„ì„œê´€", "ë°•ë¬¼ê´€", "ì˜íšŒì‚¬ë¬´êµ­"
]

LOCATIONS = [
    "ì£¼ë•ì", "ì‚´ë¯¸ë©´", "ìˆ˜ì•ˆë³´ë©´", "ëŒ€ì†Œì›ë©´", "ì‹ ë‹ˆë©´", "ë…¸ì€ë©´", "ì•™ì„±ë©´",
    "ì¤‘ì•™íƒ‘ë©´", "ê¸ˆê°€ë©´", "ë™ëŸ‰ë©´", "ì‚°ì²™ë©´", "ì—„ì •ë©´", "ì†Œíƒœë©´",
    "ì„±ë‚´.ì¶©ì¸ë™", "êµí˜„.ì•ˆë¦¼ë™", "êµí˜„2ë™", "ìš©ì‚°ë™", "ì§€í˜„ë™", "ë¬¸í™”ë™",
    "í˜¸ì•”.ì§ë™", "ë‹¬ì²œë™", "ë´‰ë°©ë™", "ì¹ ê¸ˆ.ê¸ˆë¦‰ë™", "ì—°ìˆ˜ë™", "ëª©í–‰.ìš©íƒ„ë™"
]

# 3ë‹¨ê³„ ìƒì„¸ë„ë³„ ì„¤ì •
MODE_CONFIG = {
    "ìµœì†Œ": {
        "ì£¼ì œë‹¹_ë¬¸ì¥ìˆ˜": "1ê°œ",
        "ë¬¸ì¥ë‹¹_ê¸¸ì´": "20~30ì",
        "ì„¤ëª…": "í•µì‹¬ í‚¤ì›Œë“œë§Œ ê°„ë‹¨íˆ ì„œìˆ "
    },
    "ê°„ëµ": {
        "ì£¼ì œë‹¹_ë¬¸ì¥ìˆ˜": "1~2ê°œ",
        "ë¬¸ì¥ë‹¹_ê¸¸ì´": "30~60ì",
        "ì„¤ëª…": "ìš”ì ê³¼ ê°„ë‹¨í•œ ë°°ê²½ì„ í¬í•¨í•˜ì—¬ ìš”ì•½"
    },
    "í‘œì¤€": {
        "ì£¼ì œë‹¹_ë¬¸ì¥ìˆ˜": "4~6ê°œ",
        "ë¬¸ì¥ë‹¹_ê¸¸ì´": "200~300ì ì´ìƒ",
        "ì„¤ëª…": "ë°°ê²½â†’í˜„í™©â†’ë¬¸ì œì â†’ëŒ€ì‘â†’í–¥í›„ ê³„íšê¹Œì§€ ì¢…í•©ì ìœ¼ë¡œ ê¸°ìˆ "
    }
}

# ì…ë ¥ ê¸¸ì´ ê¸°ì¤€
INPUT_LENGTH_THRESHOLDS = {
    "ì•„ì£¼ì§§ìŒ": 50,
    "ì§§ìŒ": 200,
    "ë³´í†µ": 500,
    "ê¸´í¸": 2000,
}


# ===== Pydantic ëª¨ë¸ =====
class SummarizeRequest(BaseModel):
    text: str
    summary_mode: str = "í‘œì¤€"
    focus_pattern: Optional[str] = None
    extract_actions: bool = True
    directive_mode: bool = False
    auto_adjust_mode: bool = True


class ActionItem(BaseModel):
    task: str
    assignee: str
    deadline: str
    details: str


class SummarizeResponse(BaseModel):
    summary: str
    actions: List[ActionItem] = []
    analysis_stats: Dict[str, Any]


# ===== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ =====
def detect_input_length_category(text: str) -> str:
    """ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜"""
    char_count = len(text.strip())
    if char_count < INPUT_LENGTH_THRESHOLDS["ì•„ì£¼ì§§ìŒ"]:
        return "ì•„ì£¼ì§§ìŒ"
    elif char_count < INPUT_LENGTH_THRESHOLDS["ì§§ìŒ"]:
        return "ì§§ìŒ"
    elif char_count < INPUT_LENGTH_THRESHOLDS["ë³´í†µ"]:
        return "ë³´í†µ"
    else:
        return "ê¸´í¸"


def get_effective_mode(original_mode: str, text: str, auto_adjust: bool = True) -> tuple:
    """ì…ë ¥ ê¸¸ì´ì— ë”°ë¼ ì‹¤ì œ ì ìš©í•  ëª¨ë“œ ê²°ì •"""
    if not auto_adjust:
        return original_mode, ""
    
    length_category = detect_input_length_category(text)
    
    if length_category == "ì•„ì£¼ì§§ìŒ":
        if original_mode in ["í‘œì¤€", "ê°„ëµ"]:
            return "ìµœì†Œ", f"ì…ë ¥ì´ ë§¤ìš° ì§§ì•„ '{original_mode}' â†’ 'ìµœì†Œ' ëª¨ë“œë¡œ ìë™ ì¡°ì •ë¨"
        return "ìµœì†Œ", ""
    elif length_category == "ì§§ìŒ":
        if original_mode == "í‘œì¤€":
            return "ê°„ëµ", f"ì…ë ¥ì´ ì§§ì•„ 'í‘œì¤€' â†’ 'ê°„ëµ' ëª¨ë“œë¡œ ìë™ ì¡°ì •ë¨"
        return original_mode, ""
    elif length_category == "ë³´í†µ":
        if original_mode == "í‘œì¤€":
            return "ê°„ëµ", f"ì…ë ¥ ê¸¸ì´ì— ë§ì¶° 'í‘œì¤€' â†’ 'ê°„ëµ' ëª¨ë“œë¡œ ì¡°ì •ë¨"
        return original_mode, ""
    else:
        return original_mode, ""


def get_anti_hallucination_instruction(length_category: str) -> str:
    """ì…ë ¥ ê¸¸ì´ì— ë”°ë¥¸ í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€ ì§€ì¹¨"""
    if length_category in ["ì•„ì£¼ì§§ìŒ", "ì§§ìŒ"]:
        return """
## âš ï¸ ì¤‘ìš”: ì§§ì€ ì…ë ¥ ì²˜ë¦¬ ê·œì¹™
- ì…ë ¥ëœ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”. ì—†ëŠ” ë‚´ìš©ì„ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
- ì…ë ¥ì´ ì§§ìœ¼ë©´ ì¶œë ¥ë„ ì§§ì•„ì•¼ í•©ë‹ˆë‹¤.
- ì›ë¬¸ì— ì–¸ê¸‰ë˜ì§€ ì•Šì€ ë¶€ì„œëª…, ì¼ì •, êµ¬ì²´ì  ìˆ˜ì¹˜, í–‰ì‚¬ëª…, ë‹´ë‹¹ì ë“±ì„ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
"""
    elif length_category == "ë³´í†µ":
        return """
## ì£¼ì˜: ë‚´ìš© ì¶©ì‹¤ë„
- ì›ë¬¸ì— ìˆëŠ” ë‚´ìš©ë§Œ ìš”ì•½í•˜ì„¸ìš”.
- ì–¸ê¸‰ë˜ì§€ ì•Šì€ ì„¸ë¶€ì‚¬í•­ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
"""
    else:
        return """
## ì°¸ê³ : ì›ë¬¸ ì¶©ì‹¤ë„
- ì›ë¬¸ì˜ ë‚´ìš©ì„ ì¶©ì‹¤íˆ ë°˜ì˜í•˜ë˜, ì¶”ì¸¡ì„± ë‚´ìš©ì€ í”¼í•˜ì„¸ìš”.
"""


# ë°œí™”ì íŒ¨í„´
_SP_LABEL = re.compile(r"^\s*(ì°¸ì„ì\s*\d+|ì‹œì¥|ë¶€ì‹œì¥|ê³¼ì¥|íŒ€ì¥|ì£¼ë¬´ê´€|\d{1,3}:|[ê°€-í£]+\s*:)")


def _propagate_last_label(text: str) -> str:
    """ë¼ë²¨ì´ í•œ ë²ˆë§Œ ì°íŒ í…ìŠ¤íŠ¸ -> ê° ì¤„ì— ë¼ë²¨ ë³µì œ"""
    out, last = [], ""
    for ln in text.splitlines():
        ln = ln.strip()
        if not ln:
            continue
        if _SP_LABEL.match(ln):
            last = _SP_LABEL.match(ln).group(1)
            out.append(ln)
        else:
            out.append(f"{last} {ln}" if last else ln)
    return "\n".join(out)


def _split_by_speaker(text: str) -> List[tuple]:
    """ë°œí™”ìë³„ë¡œ í…ìŠ¤íŠ¸ ë¶„í• """
    blocks, spk, buf = [], None, []
    for ln in text.splitlines():
        ln = ln.strip()
        if not ln:
            continue
        if m := _SP_LABEL.match(ln):
            if spk and buf:
                blocks.append((spk, "\n".join(buf).strip()))
            spk, buf = m.group(1).strip(), [ln]
        else:
            buf.append(ln)
    if spk and buf:
        blocks.append((spk, "\n".join(buf).strip()))
    return blocks


def _filter_focus(text: str, pattern: Optional[str]) -> str:
    """íŠ¹ì • ë°œí™”ìì— ì§‘ì¤‘"""
    if not pattern:
        return text
    try:
        rg = re.compile(pattern, re.I)
        filtered_blocks = []
        for spk, blk in _split_by_speaker(text):
            if rg.search(spk):
                filtered_blocks.append(blk)
        return "\n\n".join(filtered_blocks) if filtered_blocks else text
    except:
        return text


def _is_similar(term1: str, term2: str) -> bool:
    """ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ ì²´í¬"""
    if abs(len(term1) - len(term2)) > 2:
        return False
    if len(term1) < 2 or len(term2) < 2:
        return False
    same_chars = sum(1 for c1, c2 in zip(term1, term2) if c1 == c2)
    similarity = same_chars / max(len(term1), len(term2))
    return similarity >= 0.7


def enhance_text_with_terms(text: str) -> tuple:
    """ì¶©ì£¼ íŠ¹í™”ìš©ì–´ë¡œ í…ìŠ¤íŠ¸ ë³´ì •"""
    enhanced_text = text
    corrections = []
    
    potential_terms = re.findall(r'[ê°€-í£]{2,8}', text)
    unique_terms = list(set(potential_terms))[:30]
    
    for term in unique_terms:
        for dept in DEPARTMENTS:
            if _is_similar(term, dept) and term != dept:
                enhanced_text = enhanced_text.replace(term, dept)
                corrections.append(f"{term}â†’{dept}")
                break
        
        for loc in LOCATIONS:
            if _is_similar(term, loc) and term != loc:
                enhanced_text = enhanced_text.replace(term, loc)
                corrections.append(f"{term}â†’{loc}")
                break
    
    return enhanced_text, corrections[:10]


def build_summary_prompt(text: str, mode: str, focus_pattern: Optional[str], is_focused: bool) -> str:
    """ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    config = MODE_CONFIG[mode]
    length_category = detect_input_length_category(text)
    anti_hallucination = get_anti_hallucination_instruction(length_category)
    
    short_note = ""
    if length_category in ["ì•„ì£¼ì§§ìŒ", "ì§§ìŒ"]:
        short_note = f"""
## ğŸ“Œ ì…ë ¥ ê¸¸ì´ ì°¸ê³ 
í˜„ì¬ ì…ë ¥ì€ **{len(text)}ì**ë¡œ ì§§ì€ í¸ì…ë‹ˆë‹¤. 
- ì¶œë ¥ ë¶„ëŸ‰ë„ ì´ì— ë§ê²Œ ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”.
"""
    
    if is_focused:
        return f"""ë‹¹ì‹ ì€ í–‰ì •ê¸°ê´€ íšŒì˜ë¡ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒì€ íŠ¹ì • ë°œí™”ì({focus_pattern})ì˜ ë°œì–¸ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë°œí™”ìì˜ ë°œì–¸ì„ ì£¼ì œë³„ë¡œ ë¶„ë¥˜í•˜ê³  {mode} ìˆ˜ì¤€ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
{anti_hallucination}
{short_note}
## ìš”ì•½ ì›ì¹™:
1. **ì£¼ì œ ì¶”ì¶œ**: ë°œí™”ìì˜ ë°œì–¸ì„ ë…¼ë¦¬ì  ì£¼ì œë¡œ ë¶„ë¥˜
2. **{mode} ìƒì„¸ë„**: {config['ì„¤ëª…']} - ê° ì£¼ì œë³„ë¡œ {config['ì£¼ì œë‹¹_ë¬¸ì¥ìˆ˜']} ({config['ë¬¸ì¥ë‹¹_ê¸¸ì´']})
3. **ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì²´**: í–‰ì •ë¬¸ì„œì²´ì´ì§€ë§Œ ì½ê¸° ì‰½ê²Œ ì‘ì„±
4. **ì›ë¬¸ ì¶©ì‹¤**: ì›ë¬¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ì•ŠìŒ

## ë¬¸ì²´ ê°€ì´ë“œ:
- ì¢…ê²°ì–´ë¯¸: "~í•˜ë„ë¡ í•  ì˜ˆì •", "~ì— ëŒ€í•´ ë…¼ì˜í•¨", "~ì„ ì¶”ì§„ ì¤‘" ë“±
- êµ¬ì–´ì²´ ë°°ì œ: ë¬¸ì„œì²´ë¡œ ë³€í™˜

## ì¶œë ¥ í˜•ì‹:
â–£ ì£¼ì œëª…
â—¦ ë‚´ìš© ì„¤ëª…

---
ë°œí™”ì ë°œì–¸ ë‚´ìš©:
{text}
---
ë°œí™”ìì˜ ë°œì–¸ì„ ì£¼ì œë³„ë¡œ ë¶„ë¥˜í•˜ê³  {mode} ìƒì„¸ë„ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš” (ì›ë¬¸ì— ì—†ëŠ” ë‚´ìš© ì¶”ê°€ ê¸ˆì§€):"""
    
    else:
        return f"""ë‹¹ì‹ ì€ í–‰ì •ê¸°ê´€ íšŒì˜ë¡ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì „ì²´ íšŒì˜ë¡ì˜ í•µì‹¬ ë‚´ìš©ì„ ì£¼ì œë³„ë¡œ ë¶„ë¥˜í•˜ì—¬ {mode} ìˆ˜ì¤€ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
{anti_hallucination}
{short_note}
## ìš”ì•½ ì›ì¹™:
1. **ì£¼ì œ ì¶”ì¶œ**: íšŒì˜ ì „ì²´ ë‚´ìš©ì„ ë…¼ë¦¬ì  ì£¼ì œë¡œ ë¶„ë¥˜
2. **{mode} ìƒì„¸ë„**: {config['ì„¤ëª…']} - ê° ì£¼ì œë³„ë¡œ {config['ì£¼ì œë‹¹_ë¬¸ì¥ìˆ˜']} ({config['ë¬¸ì¥ë‹¹_ê¸¸ì´']})
3. **ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì²´**: í–‰ì •ë¬¸ì„œì²´ì´ì§€ë§Œ ì½ê¸° ì‰½ê²Œ ì‘ì„±
4. **ê· í˜•ê°**: ëª¨ë“  ì°¸ì„ìì˜ ì¤‘ìš” ë°œì–¸ì„ ì ì ˆíˆ ë°˜ì˜
5. **ì›ë¬¸ ì¶©ì‹¤**: ì›ë¬¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ì•ŠìŒ

## ë¬¸ì²´ ê°€ì´ë“œ:
- ì¢…ê²°ì–´ë¯¸: "~í•˜ë„ë¡ í•  ì˜ˆì •", "~ì— ëŒ€í•´ ë…¼ì˜í•¨", "~ì„ ì¶”ì§„ ì¤‘" ë“±
- êµ¬ì–´ì²´ ë°°ì œ: ë¬¸ì„œì²´ë¡œ ë³€í™˜

## ì¶œë ¥ í˜•ì‹:
â–£ ì£¼ì œëª…
â—¦ ë‚´ìš© ì„¤ëª…

---
ì „ì²´ íšŒì˜ë¡:
{text}
---
íšŒì˜ ë‚´ìš©ì„ ì£¼ì œë³„ë¡œ ë¶„ë¥˜í•˜ê³  {mode} ìƒì„¸ë„ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš” (ì›ë¬¸ì— ì—†ëŠ” ë‚´ìš© ì¶”ê°€ ê¸ˆì§€):"""


def build_directive_prompt(text: str, mode: str, focus_pattern: Optional[str], is_focused: bool) -> str:
    """ì§€ì‹œì‚¬í•­ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    length_category = detect_input_length_category(text)
    anti_hallucination = get_anti_hallucination_instruction(length_category)
    
    length_note = ""
    if length_category in ["ì•„ì£¼ì§§ìŒ", "ì§§ìŒ", "ë³´í†µ"]:
        length_note = f"""
## ğŸ“Œ ì…ë ¥ ê¸¸ì´ ì°¸ê³ 
í˜„ì¬ ì…ë ¥ì€ **{len(text)}ì**ì…ë‹ˆë‹¤.
- ì…ë ¥ì´ ì§§ìœ¼ë©´ ì¶œë ¥ë„ ì§§ê²Œ ìœ ì§€í•˜ì„¸ìš”.
- í˜•ì‹ì„ ì±„ìš°ê¸° ìœ„í•´ ì—†ëŠ” ë‚´ìš©ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
"""
    
    who = f" (ëŒ€ìƒ ë°œí™”ì: {focus_pattern})" if (is_focused and focus_pattern) else ""
    scope = "í•´ë‹¹ ë°œí™”ìì˜ ë°œì–¸ì—ì„œ" if is_focused else "ì „ì²´ íšŒì˜ë¡ì—ì„œ"
    
    return f"""ë‹¹ì‹ ì€ í–‰ì •ê¸°ê´€ íšŒì˜ë¡ì„ 'ì§€ì‹œì‚¬í•­' í˜•íƒœë¡œ ì •ë¦¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{anti_hallucination}
{length_note}
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê²€í† í•˜ì—¬ {scope} ì£¼ì œë³„ í•µì‹¬ ë‚´ìš©ì„ ì •ë¦¬í•˜ë˜, 
**ì›ë¬¸ì— ìˆëŠ” ë‚´ìš©ë§Œ** ì§€ì‹œì‚¬í•­ í˜•íƒœë¡œ ë³€í™˜í•˜ì„¸ìš”.

## ì‘ì„± ê·œì¹™
- ì›ë¬¸ì— ë‚´ìš©ì´ ì¶©ë¶„í•˜ë©´: ê° ì£¼ì œë³„ 4~6ë¬¸ì¥
- ì›ë¬¸ì´ ì§§ìœ¼ë©´: ì›ë¬¸ ê¸¸ì´ì— ë§ê²Œ ê°„ê²°í•˜ê²Œ ì‘ì„±
- "~ì„/~ë¨/~í•„ìš”í•¨/~ë°”ëŒ" í‘œí˜„ì€ "~í•  ê²ƒ"ìœ¼ë¡œ ë³€í™˜
- **ì›ë¬¸ì— ì—†ëŠ” êµ¬ì²´ì  ë‚ ì§œ, ìˆ˜ì¹˜, ë¶€ì„œëª…, ë‹´ë‹¹ìë¥¼ ìƒì„±í•˜ì§€ ë§ ê²ƒ**

## ì¶œë ¥ í˜•ì‹
â–£ ì£¼ì œëª…
â—¦ ì§€ì‹œí˜•ìœ¼ë¡œ ë³€í™˜ëœ ë‚´ìš©

---
ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸{who}:
{text}
---
ìœ„ ì§€ì¹¨ì— ë”°ë¼ ì›ë¬¸ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ì§€ì‹œì‚¬í•­ í˜•íƒœë¡œ ë³€í™˜:"""


def extract_action_items(summary: str) -> List[Dict[str, str]]:
    """ìš”ì•½ì—ì„œ ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ"""
    actions = []
    
    action_patterns = [
        r'([^.]*(?:ì¶”ì§„|ì‹œí–‰|ì‹¤ì‹œ|ê²€í† |ì¤€ë¹„|ì‘ì„±|ì œì¶œ|ë³´ê³ |ê°œì„ |ê°•í™”|í™•ëŒ€|ë§ˆë ¨|ì„¤ì¹˜|êµ¬ì¶•)[^.]*?)(?:í•˜ê¸°\s*)?(?:ë°”ëŒ|í• \s*ê²ƒ|í•˜ê¸°ë¡œ\s*í•¨|í•„ìš”í•¨)',
        r'([^.]*(?:ê¹Œì§€|ë‚´|ì¤‘|ì—°ë‚´|ìƒë°˜ê¸°|í•˜ë°˜ê¸°)[^.]*(?:ì™„ë£Œ|ë§ˆë¬´ë¦¬|ì¶”ì§„|ì œì¶œ|ê²°ì •)[^.]*)',
        r'([^.]*(?:ê³¼|íŒ€|ë¶€|ì„¼í„°|ì²­)(?:ì—ì„œëŠ”?)?\s*[^.]*(?:ë‹´ë‹¹|ì²˜ë¦¬|ì‹œí–‰)[^.]*)'
    ]
    
    action_count = 0
    for pattern in action_patterns:
        matches = re.finditer(pattern, summary, re.IGNORECASE)
        for match in matches:
            if action_count >= 8:
                break
            
            full_match = match.group(1).strip()
            if len(full_match) > 10:
                assignee_match = re.search(r'([ê°€-í£]+(?:ê³¼|íŒ€|ë¶€|ì„¼í„°|ì²­))', full_match)
                assignee = assignee_match.group(1) if assignee_match else "ë¯¸ì§€ì •"
                
                deadline_match = re.search(r'(\d+ì›”\s*\d+ì¼|\d+ì¼ê¹Œì§€|ë‹¤ìŒì£¼|ë‚´ì£¼|ì—°ë‚´|ìƒë°˜ê¸°|í•˜ë°˜ê¸°)', full_match)
                deadline = deadline_match.group(1) if deadline_match else "ë¯¸ì§€ì •"
                
                actions.append({
                    "task": full_match,
                    "assignee": assignee,
                    "deadline": deadline,
                    "details": full_match
                })
                action_count += 1
    
    return actions


def validate_summary(summary: str, mode: str, is_focused: bool, length_category: str) -> tuple:
    """ìš”ì•½ ê²°ê³¼ ê²€ì¦"""
    try:
        topics = summary.count("â–£")
        bullets = summary.count("â—¦")
        
        if topics < 1:
            return False, "ì£¼ì œê°€ ì—†ìŠµë‹ˆë‹¤"
        if bullets < 1:
            return False, "ì„¸ë¶€ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"
        
        content_length = len(summary.replace("â–£", "").replace("â—¦", "").strip())
        
        if length_category in ["ì•„ì£¼ì§§ìŒ", "ì§§ìŒ"]:
            if content_length < 10:
                return False, "ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤"
            if content_length > 500:
                return False, "ì…ë ¥ ëŒ€ë¹„ ì¶œë ¥ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤"
            return True, "ê°„ë‹¨ ìš”ì•½ ê²€ì¦ í†µê³¼"
        
        if is_focused:
            if content_length < 30:
                return False, "ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤"
            if content_length > 3000:
                return False, "ë‚´ìš©ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤"
        else:
            if content_length < 50:
                return False, "ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤"
            if content_length > 5000:
                return False, "ë‚´ìš©ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤"
        
        return True, "êµ¬ì¡° ê²€ì¦ í†µê³¼"
    except Exception as e:
        return True, f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ (í†µê³¼ ì²˜ë¦¬): {str(e)}"


def _format_basic_summary(summary: str) -> str:
    """ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ ìš”ì•½ ì •ë¦¬"""
    lines = [line.strip() for line in summary.split('\n') if line.strip()]
    
    formatted_lines = []
    for line in lines:
        if not line.startswith('â–£') and not line.startswith('â—¦'):
            if len(line) > 20:
                formatted_lines.append(f"â—¦ {line}")
        else:
            formatted_lines.append(line)
    
    if not any(line.startswith('â–£') for line in formatted_lines):
        formatted_lines.insert(0, "â–£ íšŒì˜ ì£¼ìš” ë‚´ìš©")
    
    return '\n'.join(formatted_lines)


# ===== API ì—”ë“œí¬ì¸íŠ¸ =====
@router.get("/modes")
async def get_modes():
    """ìš”ì•½ ëª¨ë“œ ëª©ë¡ ì¡°íšŒ"""
    return {
        "modes": [
            {"value": "ìµœì†Œ", "label": "ìµœì†Œ", "description": MODE_CONFIG["ìµœì†Œ"]["ì„¤ëª…"]},
            {"value": "ê°„ëµ", "label": "ê°„ëµ", "description": MODE_CONFIG["ê°„ëµ"]["ì„¤ëª…"]},
            {"value": "í‘œì¤€", "label": "í‘œì¤€", "description": MODE_CONFIG["í‘œì¤€"]["ì„¤ëª…"]},
        ]
    }


@router.get("/system-info")
async def get_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ"""
    return {
        "departments_count": len(DEPARTMENTS),
        "locations_count": len(LOCATIONS),
        "features": [
            "ë¶€ì„œëª… ì¸ì‹",
            "ì§€ì—­ëª… ì¸ì‹",
            "GPT-4o ê³ ê¸‰ ìš”ì•½",
            "êµ¬ì¡°í™” ìš”ì•½",
            "í›„ì²˜ë¦¬ ê²€ì¦"
        ]
    }


@router.post("/summarize", response_model=SummarizeResponse)
async def summarize_meeting(request: SummarizeRequest):
    """íšŒì˜ë¡ ìš”ì•½"""
    if not request.text.strip():
        raise HTTPException(status_code=400, detail="íšŒì˜ë¡ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    start_time = time.time()
    
    try:
        # 1) ì „ì²˜ë¦¬
        prepped = _propagate_last_label(request.text)
        
        # ë°œí™”ì í•„í„°ë§
        if request.focus_pattern:
            text_to_summarize = _filter_focus(prepped, request.focus_pattern)
            is_focused = True
            if not text_to_summarize.strip() or text_to_summarize == prepped:
                text_to_summarize = prepped
                is_focused = False
        else:
            text_to_summarize = prepped
            is_focused = False
        
        # 2) ìš©ì–´ ë³´ì •
        enhanced_text, corrections = enhance_text_with_terms(text_to_summarize)
        
        # 3) ëª¨ë“œ ìë™ ì¡°ì •
        length_category = detect_input_length_category(enhanced_text)
        effective_mode, mode_msg = get_effective_mode(
            request.summary_mode, 
            enhanced_text, 
            request.auto_adjust_mode
        )
        
        # 4) í”„ë¡¬í”„íŠ¸ ìƒì„±
        if request.directive_mode:
            prompt = build_directive_prompt(enhanced_text, effective_mode, request.focus_pattern, is_focused)
        else:
            prompt = build_summary_prompt(enhanced_text, effective_mode, request.focus_pattern, is_focused)
        
        # í† í° ìˆ˜ ì¡°ì •
        if length_category in ["ì•„ì£¼ì§§ìŒ", "ì§§ìŒ"]:
            max_tokens = 500
        elif length_category == "ë³´í†µ":
            max_tokens = 1000
        else:
            max_tokens = SUMMARY_TOKENS if is_focused else SUMMARY_TOKENS * 2
        
        temperature = 0.2 if length_category in ["ì•„ì£¼ì§§ìŒ", "ì§§ìŒ"] else 0.3
        
        # 5) GPT í˜¸ì¶œ
        response = client.chat.completions.create(
            model=FULL_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=max_tokens,
        )
        
        summary = response.choices[0].message.content.strip()
        
        # 6) ê²€ì¦
        is_valid, validation_msg = validate_summary(summary, effective_mode, is_focused, length_category)
        if not is_valid:
            summary = _format_basic_summary(summary)
            validation_msg = "ê¸°ë³¸ í˜•ì‹ ì ìš©"
        
        # 7) ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ
        actions = []
        if request.extract_actions and length_category not in ["ì•„ì£¼ì§§ìŒ"]:
            action_dicts = extract_action_items(summary)
            actions = [ActionItem(**a) for a in action_dicts]
        
        # 8) í†µê³„
        speakers = _split_by_speaker(prepped)
        processing_time = time.time() - start_time
        
        summary_type = "ë°œí™”ì ì§‘ì¤‘ ìš”ì•½" if is_focused else "ì „ì²´ íšŒì˜ ìš”ì•½"
        
        analysis_stats = {
            "speaker_count": len(speakers),
            "topic_count": summary.count("â–£"),
            "keyword_count": len(corrections),
            "processing_time": round(processing_time, 1),
            "validation_status": validation_msg,
            "corrections": corrections[:5],
            "summary_type": summary_type,
            "input_length": len(request.text),
            "input_category": length_category,
            "effective_mode": effective_mode,
            "original_mode": request.summary_mode,
            "mode_adjustment": mode_msg,
        }
        
        return SummarizeResponse(
            summary=summary.replace("\n", "  \n"),
            actions=actions,
            analysis_stats=analysis_stats
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìš”ì•½ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")


@router.post("/summarize-file")
async def summarize_file(
    file: UploadFile = File(...),
    summary_mode: str = Form(default="í‘œì¤€"),
    focus_pattern: str = Form(default=""),
    extract_actions: bool = Form(default=True),
    directive_mode: bool = Form(default=False),
    auto_adjust_mode: bool = Form(default=True)
):
    """íŒŒì¼ ì—…ë¡œë“œ í›„ íšŒì˜ë¡ ìš”ì•½"""
    if not file.filename.endswith('.txt'):
        raise HTTPException(status_code=400, detail="txt íŒŒì¼ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
    
    try:
        contents = await file.read()
        text = contents.decode('utf-8')
        
        # ìš”ì•½ ìš”ì²­ ìƒì„±
        request = SummarizeRequest(
            text=text,
            summary_mode=summary_mode,
            focus_pattern=focus_pattern if focus_pattern else None,
            extract_actions=extract_actions,
            directive_mode=directive_mode,
            auto_adjust_mode=auto_adjust_mode
        )
        
        return await summarize_meeting(request)
        
    except UnicodeDecodeError:
        raise HTTPException(status_code=400, detail="íŒŒì¼ ì¸ì½”ë”©ì„ í™•ì¸í•´ì£¼ì„¸ìš”. UTF-8ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
