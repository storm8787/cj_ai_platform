"""ë³´ë„ìë£Œ ìƒì„± API - ì™„ë²½ êµ¬í˜„"""
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional, List, Dict
import datetime

from services.vectorstore import VectorStoreService
from services.openai_service import OpenAIService
from services.supabase_service import SupabaseService
from utils.prompt_filter import check_text_security

router = APIRouter()

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
vectorstore = VectorStoreService()
openai_service = OpenAIService()
supabase_service = SupabaseService()


class SearchRequest(BaseModel):
    query: str
    top_k: int = 3


class GenerateRequest(BaseModel):
    title: str
    department: str = ""
    manager: str = ""
    paragraphs: str = "4ê°œì´ìƒ"
    length: str = "ê¸¸ê²Œ"
    content: str
    additional: str = ""


class DocumentReference(BaseModel):
    """ì°¸ì¡° ë¬¸ì„œ ì •ë³´"""
    index: int
    similarity: float
    doc_id: str
    preview: str
    full_content: str


class GenerateResponse(BaseModel):
    """ë³´ë„ìë£Œ ìƒì„± ì‘ë‹µ"""
    result: str
    references: List[DocumentReference]
    search_method: str
    vectorstore_status: Dict
    generation_time: float
    supabase_log_id: Optional[int] = None


@router.post("/search-similar")
async def search_similar_documents(request: SearchRequest):
    """ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
    # ì…ë ¥ê°’ ê²€ì¦
    is_safe, message = check_text_security(request.query)
    if not is_safe:
        raise HTTPException(status_code=400, detail=message)
    
    try:
        documents = await vectorstore.search_press_release(
            query=request.query,
            top_k=request.top_k
        )
        return {"documents": documents}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/generate", response_model=GenerateResponse)
async def generate_press_release(request: GenerateRequest):
    """ë³´ë„ìë£Œ ìƒì„± - ì™„ë²½ êµ¬í˜„"""
    import time
    start_time = time.time()
    
    # ì…ë ¥ê°’ ê²€ì¦
    for text in [request.title, request.content, request.additional]:
        if text:
            is_safe, message = check_text_security(text)
            if not is_safe:
                raise HTTPException(status_code=400, detail=message)
    
    try:
        # 1. ë²¡í„°ìŠ¤í† ì–´ ìƒíƒœ í™•ì¸
        vectorstore_status = vectorstore.get_press_release_status()
        search_method = "ğŸ¤– AI ë²¡í„° ê²€ìƒ‰" if vectorstore_status.get("loaded") else "ğŸ“Š ê¸°ë³¸ ê²€ìƒ‰"
        
        # 2. ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        similar_docs = await vectorstore.search_press_release(
            query=request.title,
            top_k=3
        )
        
        # 3. ì°¸ì¡° ë¬¸ì„œ ì •ë³´ êµ¬ì„±
        references = []
        examples_for_prompt = []
        
        for i, doc in enumerate(similar_docs):
            content = doc.get('content', '')
            similarity = doc.get('similarity', 0.0)
            
            # ì°¸ì¡° ë¬¸ì„œ ì •ë³´
            references.append({
                "index": i + 1,
                "similarity": round(similarity, 4),
                "doc_id": doc.get('metadata', {}).get('id', f'doc_{i+1}'),
                "preview": content[:200] + "..." if len(content) > 200 else content,
                "full_content": content
            })
            
            # í”„ë¡¬í”„íŠ¸ìš© ì˜ˆì‹œ (ì „ì²´ ë‚´ìš©, ìµœëŒ€ 1000ì)
            examples_for_prompt.append(content[:1000])
        
        # 4. í”„ë¡¬í”„íŠ¸ ìƒì„± (ê¸°ì¡´ ê°œì„ ëœ ë²„ì „)
        examples_combined = "\n\n---\n\n".join(examples_for_prompt)
        content_points = [line.strip() for line in request.content.strip().split("\n") if line.strip()]
        joined_points = "\n- ".join(content_points)
        
        # ê¸¸ì´ ì§€ì‹œ
        length_chars = {
            "ì§§ê²Œ": 600,
            "ì¤‘ê°„": 800,
            "ê¸¸ê²Œ": 1000
        }.get(request.length, 1000)
        
        # ë¬¸ë‹¨ ì§€ì‹œ
        paragraph_instruction = {
            "4ê°œì´ìƒ": "ì „ì²´ ê¸€ì€ 4ê°œ ì´ìƒì˜ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.\n",
            "3ê°œ": "ì „ì²´ ê¸€ì€ 3ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.\n",
            "2ê°œ": "ì „ì²´ ê¸€ì€ 2ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.\n",
            "1ê°œ": "ì „ì²´ ê¸€ì€ 1ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.\n"
        }.get(request.paragraphs, "")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = (
            "ë„ˆëŠ” ì§€ë°©ì •ë¶€ ë³´ë„ìë£Œ ì‘ì„± ì „ë¬¸ê°€ì•¼. "
            "ì•„ë˜ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ì°¸ê³ í•´, í–‰ì •ê¸°ê´€ ìŠ¤íƒ€ì¼ë¡œ ê³µê³µ ë³´ë„ìë£Œë¥¼ ì‘ì„±í•´ì¤˜."
        )
        
        # ì¶”ê°€ ì§€ì‹œì‚¬í•­
        additional_instructions = (
            f"ë³´ë„ìë£Œì—ëŠ” ìƒë‹¨ì˜ ë³´ë„ì¼ì, ë‹´ë‹¹ì ì •ë³´, ì—°ë½ì²˜ëŠ” í¬í•¨í•˜ì§€ ë§ê³  ë³¸ë¬¸ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
            f"ë‹´ë‹¹ì ì¸ìš©ë¬¸ì´ ë‚˜ì˜¬ ê²½ìš°, ë‹´ë‹¹ì ì´ë¦„ì€ '{request.manager}'ì´ê³ , "
            f"ì§ì±…ì€ '{request.department}ì¥'ìœ¼ë¡œ í‘œê¸°í•´ì£¼ì„¸ìš”.\n"
            f"ë‹´ë‹¹ì ì¸ìš©ë¬¸ì´ ë‚˜ì˜¬ ê²½ìš°, '{request.manager}' í•œì¹¸ë„ê³  '{request.department}ì¥'ìœ¼ë¡œ í‘œê¸°í•´ì£¼ì„¸ìš”. "
            f"ì˜ˆ: ê¹€íƒœê·  ìì¹˜í–‰ì •ê³¼ì¥\n"
            f"ì „ì²´ ë¬¸ì²´ëŠ” ë³´ë„ìë£Œ ìŠ¤íƒ€ì¼ì˜ ê°„ì ‘í™”ë²•ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”. ì˜ˆ: '~í–ˆë‹¤', '~ë¼ê³  ë°í˜”ë‹¤' ë“±.\n"
            f"{paragraph_instruction}"
            f"ë³´ë„ìë£ŒëŠ” ë°˜ë“œì‹œ '[ì œëª©] ë³¸ë¬¸ì œëª©'ìœ¼ë¡œ ì‹œì‘í•œ í›„, í•œ ì¤„ ì•„ë˜ì— ë¶€ì œëª© í˜•íƒœì˜ ìš”ì•½ ë¬¸ì¥ì„ ë„£ì–´ì£¼ì„¸ìš”. "
            f"ë¶€ì œëª©ì€ '-' ê¸°í˜¸ë¡œ ì‹œì‘í•˜ì„¸ìš”.\n"
            f"ì „ì²´ ë³´ë„ìë£Œ ë¶„ëŸ‰ì€ ì•½ {length_chars}ì ë‚´ì™¸ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. í•„ìš” ì‹œ ìµœëŒ€ í† í° ìˆ˜ë¥¼ ëŠ˜ë ¤ë„ ê´œì°®ìŠµë‹ˆë‹¤.\n"
            f"ì „ì²´ ë³´ë„ìë£ŒëŠ” ë°˜ë“œì‹œ {length_chars}ì ë³´ë‹¤ëŠ” ê¸¸ê²Œ(+300ì ê°€ëŠ¥) ì‘ì„±í•´ì£¼ì„¸ìš”."
        )
        
        # ì‚¬ìš©ì ì¿¼ë¦¬ í”„ë¡¬í”„íŠ¸
        user_query_prompt = (
            f"ì…ë ¥í•œ ì œëª© í›„ë³´: {request.title}\n\n"
            f"ì•„ë˜ ë‚´ìš© í¬ì¸íŠ¸ë¥¼ ë°˜ì˜í•˜ì—¬ ë³´ë„ìë£Œì— ì–´ìš¸ë¦¬ëŠ” ì œëª©ì„ ìƒˆë¡œ ì‘ì„±í•˜ê³ , "
            f"ê·¸ ì œëª©ì„ '[ì œëª©]'ì— ë°˜ì˜í•´ì¤˜. ì…ë ¥í•œ ì œëª©ì€ ì°¸ê³ ë§Œ í•˜ê³  ê·¸ëŒ€ë¡œ ì“°ì§€ ì•Šì•„ë„ ë¼.\n\n"
            f"ë‚´ìš© í¬ì¸íŠ¸:\n- {joined_points}\n\n"
            f"ìš”ì²­ì‚¬í•­:\n- {request.additional if request.additional else 'ì—†ìŒ'}\n\n"
            f"{additional_instructions}"
        )
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸
        full_prompt = f"""{system_prompt}

ì•„ë˜ëŠ” ì°¸ê³ ìš© ë³´ë„ìë£Œ ì˜ˆì‹œì…ë‹ˆë‹¤:

{examples_combined}

ìœ„ ìŠ¤íƒ€ì¼ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ìš”ì²­ì‚¬í•­ì— ë§ëŠ” ìƒˆë¡œìš´ ë³´ë„ìë£Œë¥¼ ì‘ì„±í•´ì¤˜:

{user_query_prompt}
"""
        
        # 5. GPTë¡œ ìƒì„±
        result = await openai_service.generate_text(
            prompt=full_prompt,
            max_tokens=2000,
            temperature=0.5
        )
        
        # 6. ìƒì„± ì‹œê°„ ê³„ì‚°
        generation_time = round(time.time() - start_time, 2)
        
        # 7. Supabase ë¡œê¹…
        supabase_log_id = None
        try:
            # íŒŒì¼ ì €ì¥
            safe_title = request.title[:20].replace(" ", "_").replace("/", "_") if request.title else "ë³´ë„ìë£Œ"
            file_name = f"{safe_title}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            file_bytes = result.encode('utf-8')
            
            log_result = await supabase_service.log_press_release(
                file_bytes=file_bytes,
                file_name=file_name,
                metadata={
                    "title": request.title,
                    "department": request.department,
                    "manager": request.manager,
                    "paragraphs": request.paragraphs,
                    "length": request.length,
                    "search_method": search_method,
                    "references_count": len(references),
                    "generation_time": generation_time
                }
            )
            supabase_log_id = log_result.get("id") if log_result else None
        except Exception as e:
            print(f"âš ï¸ Supabase ë¡œê¹… ì‹¤íŒ¨: {e}")
        
        # 8. ì‘ë‹µ ë°˜í™˜
        return GenerateResponse(
            result=result,
            references=references,
            search_method=search_method,
            vectorstore_status=vectorstore_status,
            generation_time=generation_time,
            supabase_log_id=supabase_log_id
        )
        
    except Exception as e:
        # ì—ëŸ¬ ë¡œê¹…
        try:
            await supabase_service.log_error(
                feature_name="ë³´ë„ìë£Œ ìƒì„±ê¸°",
                error_message=str(e)
            )
        except:
            pass
        
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/status")
async def get_vectorstore_status():
    """ë²¡í„°ìŠ¤í† ì–´ ìƒíƒœ í™•ì¸"""
    try:
        status = vectorstore.get_press_release_status()
        return status
    except Exception as e:
        return {"status": "error", "message": str(e)}